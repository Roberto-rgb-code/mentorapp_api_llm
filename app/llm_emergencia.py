# app/llm_emergencia.py
import os
import json
import asyncio
from typing import Dict, Any
from fastapi import HTTPException
from openai import OpenAI

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
MODEL_NAME = os.getenv("OPENAI_MODEL_NAME", "gpt-4.1-mini")

client = OpenAI(api_key=OPENAI_API_KEY)

async def analizar_diagnostico_emergencia(diagnostico_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Analiza un diagn√≥stico de EMERGENCIA con OpenAI Chat Completions
    y devuelve el JSON EXACTO que consume el frontend.
    """
    # Fallback demo si no hay API key
    if not OPENAI_API_KEY:
        return {
            "diagnostico_rapido": "Demo local sin OPENAI_API_KEY. Empresa en estr√©s de liquidez y ca√≠da de ventas.",
            "acciones_inmediatas": [
                "Congelar gastos no esenciales 14 d√≠as",
                "Priorizar cobros cr√≠ticos y renegociar pagos",
                "Comunicar a clientes clave un plan de continuidad",
            ],
            "riesgo_general": "alto",
            "recomendaciones_clave": [
                "Proteger flujo de caja semanal",
                "Ajustar capacidad operativa a demanda actual",
                "Definir plan comercial de recuperaci√≥n 30-60 d√≠as",
            ],
        }

    user_prompt = (
        "Eres un consultor de crisis empresarial. Recibes datos de un diagn√≥stico de EMERGENCIA.\n"
        "Tu objetivo: entregar un diagn√≥stico muy breve y accionable, manteniendo foco en medidas urgentes.\n\n"
        "Devuelve SOLO JSON con este esquema:\n"
        "- diagnostico_rapido: resumen ejecutivo en 4‚Äì6 l√≠neas, tono claro y directo.\n"
        "- acciones_inmediatas: 4‚Äì8 acciones priorizadas para las pr√≥ximas 24‚Äì72 horas.\n"
        "- riesgo_general: uno de ['bajo','moderado','alto','critico'].\n"
        "- recomendaciones_clave: 4‚Äì8 recomendaciones de estabilizaci√≥n para 2‚Äì4 semanas.\n\n"
        f"Datos del diagn√≥stico de emergencia:\n{json.dumps(diagnostico_data, ensure_ascii=False, indent=2)}\n\n"
        "Responde EXCLUSIVAMENTE con JSON v√°lido."
    )

    try:
        def _call():
            completion = client.chat.completions.create(
                model=MODEL_NAME,
                messages=[
                    {"role": "system", "content": "Responde solo con JSON v√°lido."},
                    {"role": "user", "content": user_prompt},
                ],
                response_format={"type": "json_object"},  # üëà ahora s√≠ v√°lido
                temperature=0.2,
            )
            return completion.choices[0].message.content

        result = await asyncio.to_thread(_call)

        return json.loads(result)

    except Exception as e:
        raise HTTPException(
            status_code=502,
            detail=f"Fallo con OpenAI ({MODEL_NAME}): {str(e)}",
        )
